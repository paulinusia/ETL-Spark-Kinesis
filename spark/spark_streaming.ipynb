{"cells":[{"cell_type":"code","source":["import sys\n","from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession\n","from pyspark.streaming import StreamingContext\n","from pyspark.streaming.kinesis import KinesisUtils, InitialPositionInStream\n","from pyspark.sql.types import *\n","from pyspark.sql.functions import UserDefinedFunction\n","from pyspark.sql.types import StringType\n","from pyspark.sql.types import IntegerType\n","from pyspark.sql.functions import *\n","\n","import json"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["spark = SparkSession.builder\\\n                    .master(\"local\")\\\n                    .appName(\"Reddit-News\")\\\n                    .getOrCreate()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["pythonSchema = StructType() \\\n          .add(\"id\", StringType(), True) \\\n          .add(\"submission\", StringType(), True) \\\n          .add(\"comment_number\", IntegerType(), True) \\\n          .add(\"score\", IntegerType(), True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["awsAccessKeyId = \"\" \nawsSecretKey = \"\"  \nkinesisStreamName = \"\" \nkinesisRegion = \"\""],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["kinesisDF = spark \\\n  .readStream \\\n  .format(\"kinesis\") \\\n  .option(\"streamName\", kinesisStreamName)\\\n  .option(\"region\", kinesisRegion) \\\n  .option(\"initialPosition\", \"latest\") \\\n  .option(\"format\", \"json\") \\\n  .option(\"awsAccessKey\", awsAccessKeyId)\\\n  .option(\"awsSecretKey\", awsSecretKey) \\\n  .option(\"inferSchema\", \"true\") \\\n  .load()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Data sourced from kinesis will come into the Spark Streaming DF here\ndf = kinesisDF \\\n  .writeStream \\\n  .format(\"memory\") \\\n  .outputMode(\"append\") \\\n  .queryName(\"news\")  \\\n  .start()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["df.status"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[18]: {&#39;message&#39;: &#39;Getting offsets from KinesisV2[reddit_news]&#39;,\n &#39;isDataAvailable&#39;: False,\n &#39;isTriggerActive&#39;: True}</div>"]}}],"execution_count":7},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#sentiment\n","news = spark.sql(\"select cast(data as string) from news\")\n"]}],"metadata":{"name":"reddit-news","notebookId":3548582142412563},"nbformat":4,"nbformat_minor":0}